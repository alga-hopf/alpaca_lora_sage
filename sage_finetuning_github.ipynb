{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alga-hopf/alpaca_lora_sage/blob/main/sage_finetuning_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8469e50-1d65-4aa8-b7ee-3f2154b7a96d"
      },
      "outputs": [],
      "source": [
        "!pip3 install datasets Accelerate bitsandbytes sentencepiece wandb\n",
        "!pip3 install git+https://github.com/huggingface/transformers\n",
        "!pip3 install git+https://github.com/huggingface/peft\n",
        "!pip3 install pynvml"
      ],
      "id": "a8469e50-1d65-4aa8-b7ee-3f2154b7a96d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oz9nj8BGYSSQ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import timeit\n",
        "import copy\n",
        "import torch\n",
        "import sys\n",
        "from transformers import Trainer, TrainingArguments, LlamaForCausalLM, LlamaTokenizer, DataCollatorWithPadding, DataCollatorForSeq2Seq, get_scheduler, AdamW\n",
        "from datasets import load_dataset, DatasetDict, Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import wandb\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "from pynvml import *\n",
        "from peft import LoraConfig, get_peft_model, get_peft_model_state_dict, prepare_model_for_kbit_training, set_peft_model_state_dict"
      ],
      "id": "Oz9nj8BGYSSQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORIhYMVk47MF"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ],
      "id": "ORIhYMVk47MF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set some custom variables before the training.\n",
        "Choose the path to the training dataset, the preferred output directory, how to save the model and the name of the wandb project and run."
      ],
      "metadata": {
        "id": "RiksnlkMySJO"
      },
      "id": "RiksnlkMySJO"
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"your path to dataset\"  # path to the training dataset\n",
        "out_dir = \"your output dir\"  # your output directory\n",
        "model_name = \"your model name\"  # how to save your pretrained model\n",
        "wandb_project = \"your wandb project\"  # name of your wandb project\n",
        "wandb_run_name = \"your wandb run name\" # name of your wandb run (can also be empty)"
      ],
      "metadata": {
        "id": "WPAxvmQ2yDxO"
      },
      "id": "WPAxvmQ2yDxO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5d67333-0c9e-44f6-b0ce-bad4b5784f78"
      },
      "source": [
        "# Load and inspect dataset"
      ],
      "id": "a5d67333-0c9e-44f6-b0ce-bad4b5784f78"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o25NPbgiYitI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "o25NPbgiYitI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f51df9d-be9a-46e3-ba6c-7676be594c33"
      },
      "outputs": [],
      "source": [
        "with open(path, 'r') as f:\n",
        "    raw_dataset = json.load(f)"
      ],
      "id": "5f51df9d-be9a-46e3-ba6c-7676be594c33"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5095501-48d0-4c69-ac17-fe19e31a9f60"
      },
      "outputs": [],
      "source": [
        "len(raw_dataset)"
      ],
      "id": "d5095501-48d0-4c69-ac17-fe19e31a9f60"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "671849d8-1dd8-4538-8213-98d92b741f7d"
      },
      "source": [
        "# Fine tuning"
      ],
      "id": "671849d8-1dd8-4538-8213-98d92b741f7d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP4Pwv4wwqd9"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ],
      "id": "JP4Pwv4wwqd9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90227a4b-df2e-4ca4-94fa-c8c4ee98aeb0"
      },
      "outputs": [],
      "source": [
        "world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
        "model_max_length = 512\n",
        "batch_size = 128\n",
        "micro_batch_size = 4  \n",
        "lora_r = 8\n",
        "lora_alpha = 16\n",
        "lora_target_modules = [\"q_proj\", \"v_proj\"]\n",
        "lora_dropout = 0.05\n",
        "ddp = world_size != 1"
      ],
      "id": "90227a4b-df2e-4ca4-94fa-c8c4ee98aeb0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bcbb8f1-9d48-4385-a1c3-847c41200066"
      },
      "outputs": [],
      "source": [
        "tokenizer = LlamaTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\", model_max_length=model_max_length, padding_side=\"right\", use_fast=False)\n",
        "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
        "DEFAULT_EOS_TOKEN = \"</s>\"\n",
        "DEFAULT_BOS_TOKEN = \"<s>\"\n",
        "DEFAULT_UNK_TOKEN = \"<unk>\"\n",
        "tokenizer.pad_token = DEFAULT_PAD_TOKEN\n",
        "tokenizer.eos_token = DEFAULT_EOS_TOKEN\n",
        "tokenizer.bos_token = DEFAULT_BOS_TOKEN\n",
        "tokenizer.unk_token = DEFAULT_UNK_TOKEN\n",
        "IGNORE_INDEX = -100"
      ],
      "id": "3bcbb8f1-9d48-4385-a1c3-847c41200066"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "564db8e3-8250-451a-b695-59e7b66562c9"
      },
      "outputs": [],
      "source": [
        "PROMPT_DICT = {\n",
        "    \"prompt_input\": (\n",
        "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
        "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
        "    ),\n",
        "    \"prompt_no_input\": (\n",
        "        \"Below is an instruction that describes a task. \"\n",
        "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
        "    ),\n",
        "}\n",
        "list_data_dict = raw_dataset\n",
        "prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]\n",
        "sources_list = [prompt_no_input.format_map(example) for example in list_data_dict]\n",
        "targets = [f\"{example['output']}{tokenizer.eos_token}\" for example in list_data_dict]"
      ],
      "id": "564db8e3-8250-451a-b695-59e7b66562c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c65a77d-6715-4fc6-8d76-bd545afaba1b"
      },
      "outputs": [],
      "source": [
        "# If want to train on a smaller portion of the dataset just change pop_size\n",
        "pop_size = len(raw_dataset)\n",
        "order = list(range(pop_size))\n",
        "random.shuffle(order)\n",
        "examples_list = [s + t for s, t in zip(sources_list, targets)]\n",
        "examples, sources = [], []\n",
        "for n in order:\n",
        "  examples.append(examples_list[n])\n",
        "  sources.append(sources_list[n])\n",
        "full_examples = {}\n",
        "all_examples, all_sources = [], []\n",
        "for i in range(len(examples)):\n",
        "    all_examples.append(examples[i])\n",
        "    all_sources.append(sources[i])\n",
        "full_examples[\"example\"] = all_examples\n",
        "full_examples[\"source\"] = all_sources"
      ],
      "id": "1c65a77d-6715-4fc6-8d76-bd545afaba1b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8c37c6d-6d2a-481d-919f-90aa89530d08"
      },
      "outputs": [],
      "source": [
        "full_examples_dataset = Dataset.from_dict(full_examples)"
      ],
      "id": "a8c37c6d-6d2a-481d-919f-90aa89530d08"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "783d730d-77a4-4acc-9d5f-7ca6d20af675"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "    data_dict = tokenizer(example[\"example\"], padding=\"longest\", max_length=model_max_length, truncation=True) \n",
        "    tokenized_source = tokenizer(example[\"source\"], padding=\"longest\", max_length=model_max_length, truncation=True) \n",
        "    data_dict[\"labels\"] = [IGNORE_INDEX] * len(tokenized_source[\"input_ids\"]) + data_dict[\"input_ids\"][len(tokenized_source[\"input_ids\"]):]\n",
        "    return data_dict"
      ],
      "id": "783d730d-77a4-4acc-9d5f-7ca6d20af675"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe4ef416-8750-43ea-929e-a156c2d43114"
      },
      "outputs": [],
      "source": [
        "train_dataset = full_examples_dataset.map(tokenize_function)"
      ],
      "id": "fe4ef416-8750-43ea-929e-a156c2d43114"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtGl4DvecfQh"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.remove_columns([\"example\", \"source\"])"
      ],
      "id": "HtGl4DvecfQh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "251dc89b-fd85-404e-81ec-c59e9d546523"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True)"
      ],
      "id": "251dc89b-fd85-404e-81ec-c59e9d546523"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4ff7ac8-5724-410e-aaef-87d67e3696cd"
      },
      "outputs": [],
      "source": [
        "gradient_accumulation_steps = batch_size // micro_batch_size\n",
        "device_map = \"auto\"\n",
        "world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
        "ddp = world_size != 1\n",
        "if ddp:\n",
        "    device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps // world_size"
      ],
      "id": "b4ff7ac8-5724-410e-aaef-87d67e3696cd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07c31573-3769-4115-937a-f6735a26cecd"
      },
      "outputs": [],
      "source": [
        "model = LlamaForCausalLM.from_pretrained(\"decapoda-research/llama-7b-hf\", load_in_8bit=True, torch_dtype=torch.float16, device_map=device_map)"
      ],
      "id": "07c31573-3769-4115-937a-f6735a26cecd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "569a4a00-0e4c-4e1f-8643-fc144ce233b3"
      },
      "outputs": [],
      "source": [
        "model = prepare_model_for_kbit_training(model)\n",
        "config = LoraConfig(\n",
        "    r=lora_r,\n",
        "    lora_alpha=lora_alpha,\n",
        "    target_modules=lora_target_modules,\n",
        "    lora_dropout=lora_dropout,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "model = get_peft_model(model, config)"
      ],
      "id": "569a4a00-0e4c-4e1f-8643-fc144ce233b3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xwIN2iy0yWb"
      },
      "outputs": [],
      "source": [
        "def print_gpu_utilization():\n",
        "    nvmlInit()\n",
        "    handle = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")"
      ],
      "id": "6xwIN2iy0yWb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ_PB__4xtXl"
      },
      "outputs": [],
      "source": [
        "num_epochs = 3\n",
        "learning_rate = 3e-4\n",
        "cutoff_len = 256\n",
        "val_set_size = 0\n",
        "train_on_inputs = True  # if False, masks out inputs in loss\n",
        "add_eos_token = False\n",
        "group_by_length = False  # faster, but produces an odd training loss curve\n",
        "os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
        "resume_from_checkpoint = None \n",
        "gradient_accumulation_steps = batch_size // micro_batch_size\n",
        "use_wandb = True\n",
        "\n",
        "arguments = TrainingArguments(\n",
        "        per_device_train_batch_size=micro_batch_size,\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        warmup_steps=100,\n",
        "        num_train_epochs=num_epochs,\n",
        "        learning_rate=learning_rate,\n",
        "        fp16=True,\n",
        "        logging_strategy = \"steps\",\n",
        "        logging_steps=1,\n",
        "        optim=\"adamw_torch\",\n",
        "        evaluation_strategy=\"no\", #\"steps\" if val_set_size > 0 else \"no\",\n",
        "        save_strategy=\"no\",#\"steps\",\n",
        "        #eval_steps=200 if val_set_size > 0 else None,\n",
        "        #save_steps=200000000000,#200,\n",
        "        output_dir=out_dir,\n",
        "        save_total_limit=3,\n",
        "        load_best_model_at_end=True if val_set_size > 0 else False,\n",
        "        ddp_find_unused_parameters=False if ddp else None,\n",
        "        group_by_length=group_by_length,\n",
        "        report_to=\"wandb\" if use_wandb else None,\n",
        "        run_name=wandb_run_name if use_wandb else None,\n",
        "    )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=None,\n",
        "    args=arguments,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True),\n",
        ")\n",
        "model.config.use_cache = False\n",
        "\n",
        "old_state_dict = model.state_dict\n",
        "model.state_dict = (\n",
        "    lambda self, *_, **__: get_peft_model_state_dict(\n",
        "        self, old_state_dict()\n",
        "    )\n",
        ").__get__(model, type(model))\n",
        "\n",
        "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
        "    model = torch.compile(model)\n",
        "\n",
        "trainer.train(resume_from_checkpoint=resume_from_checkpoint)\n",
        "\n",
        "print_gpu_utilization()"
      ],
      "id": "PJ_PB__4xtXl"
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(out_dir+model_name)"
      ],
      "metadata": {
        "id": "4esN4yWx0nb4"
      },
      "id": "4esN4yWx0nb4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xM_tCdtO2Wsd"
      },
      "id": "xM_tCdtO2Wsd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}